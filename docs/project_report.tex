\documentclass[12pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cite}

% Hyperlink setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue,
}

% Code listing setup
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
}

% Title information
\title{\textbf{NLP Research Assistant: \\
Traditional Natural Language Processing Techniques \\
for Document Analysis}}
\author{Ritik Ranjan}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive analysis of traditional Natural Language Processing (NLP) and Machine Learning (ML) techniques applied to research document analysis. The project, designated as Milestone-1, explores classical approaches including Bag-of-Words, TF-IDF, Latent Dirichlet Allocation (LDA), K-Means clustering, and extractive summarization. Unlike modern Large Language Models (LLMs), this system relies entirely on interpretable, foundational methods to establish a baseline for understanding NLP capabilities and limitations. The implementation provides a modular toolkit with an interactive web interface, demonstrating both the strengths and constraints of traditional approaches. Results indicate that while classical methods offer transparency and computational efficiency, they lack semantic understanding and contextual reasoning, motivating the need for advanced Agentic AI systems in subsequent milestones.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

\subsection{Background}
Natural Language Processing has evolved significantly over the past decades, from rule-based systems to statistical methods, and more recently to deep learning and transformer-based architectures. However, understanding the foundations of classical NLP remains crucial for several reasons:

\begin{itemize}
    \item \textbf{Interpretability}: Traditional methods provide transparent, explainable results
    \item \textbf{Computational Efficiency}: Lower resource requirements compared to modern LLMs
    \item \textbf{Baseline Establishment}: Understanding what can be achieved without semantic embeddings
    \item \textbf{Domain Applicability}: Certain applications still benefit from classical approaches
\end{itemize}

\subsection{Motivation}
This project serves as the first milestone in a multi-phase exploration of NLP capabilities. By implementing and evaluating traditional techniques, we aim to:

\begin{enumerate}
    \item Establish performance baselines for document analysis tasks
    \item Identify specific limitations that motivate advanced approaches
    \item Provide a comparative framework for evaluating future AI-driven systems
    \item Demonstrate the evolution from statistical to semantic understanding
\end{enumerate}

\subsection{Objectives}
The primary objectives of this research are:

\begin{itemize}
    \item Develop a modular, extensible NLP toolkit using classical techniques
    \item Implement document loading, preprocessing, and feature extraction pipelines
    \item Apply unsupervised learning for topic modeling and clustering
    \item Generate extractive summaries using statistical heuristics
    \item Evaluate system performance using standard metrics
    \item Create an interactive interface for real-time analysis
    \item Document limitations to motivate Agentic AI development
\end{itemize}

\section{Problem Statement}

\subsection{Research Questions}
This project addresses the following research questions:

\begin{enumerate}
    \item What level of document understanding can be achieved using only traditional NLP techniques?
    \item How do different classical algorithms (LDA vs. K-Means) compare for topic discovery?
    \item What are the fundamental limitations of bag-of-words and TF-IDF representations?
    \item How can extractive summarization methods be optimized without semantic understanding?
    \item What metrics effectively evaluate the quality of unsupervised topic models?
\end{enumerate}

\subsection{Scope and Constraints}
The project scope is deliberately constrained to traditional methods:

\textbf{Included Techniques:}
\begin{itemize}
    \item Bag-of-Words (BoW) representation
    \item TF-IDF vectorization
    \item Latent Dirichlet Allocation (LDA)
    \item K-Means clustering
    \item Statistical keyword extraction
    \item Extractive summarization
\end{itemize}

\textbf{Explicitly Excluded:}
\begin{itemize}
    \item Word embeddings (Word2Vec, GloVe, FastText)
    \item Transformer models (BERT, GPT, T5)
    \item Neural networks and deep learning
    \item Semantic similarity measures
    \item Abstractive summarization
\end{itemize}

\section{Methodology}

\subsection{System Architecture}

The system follows a modular pipeline architecture with the following components:

\begin{figure}[h]
\centering
\begin{verbatim}
Input Documents
      |
      v
Document Loader (PDF/TXT/MD)
      |
      v
Text Preprocessor (Tokenization, Lemmatization)
      |
      v
Feature Extractor (TF-IDF)
      |
      +---> Topic Modeler (LDA/K-Means)
      |
      +---> Keyword Extractor
      |
      +---> Summarizer
      |
      v
Evaluator & Visualizer
      |
      v
Results Display
\end{verbatim}
\caption{System Pipeline Architecture}
\end{figure}

\subsection{Document Loading and Preprocessing}

\subsubsection{Document Loader}
The document loader supports multiple formats:
\begin{itemize}
    \item \textbf{PDF}: Using PyPDF2 and pdfplumber for text extraction
    \item \textbf{Text}: Direct UTF-8 encoded text files
    \item \textbf{Markdown}: Structured documentation files
\end{itemize}

\subsubsection{Text Preprocessing Pipeline}
The preprocessing pipeline consists of the following steps:

\begin{algorithm}
\caption{Text Preprocessing}
\begin{algorithmic}[1]
\Procedure{PreprocessText}{$text$}
    \State $tokens \gets \text{Tokenize}(text)$
    \State $tokens \gets \text{Lowercase}(tokens)$
    \State $tokens \gets \text{RemoveStopwords}(tokens)$
    \State $tokens \gets \text{RemovePunctuation}(tokens)$
    \State $tokens \gets \text{Lemmatize}(tokens)$
    \State $tokens \gets \text{FilterShortTokens}(tokens, min\_length=3)$
    \State \Return $tokens$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Feature Extraction}

\subsubsection{TF-IDF Vectorization}
Term Frequency-Inverse Document Frequency (TF-IDF) is computed as:

\begin{equation}
\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)
\end{equation}

where:
\begin{equation}
\text{TF}(t, d) = \frac{f_{t,d}}{\sum_{t' \in d} f_{t',d}}
\end{equation}

\begin{equation}
\text{IDF}(t) = \log \frac{N}{|\{d \in D : t \in d\}|}
\end{equation}

Parameters:
\begin{itemize}
    \item Maximum features: 500
    \item N-gram range: (1, 2) - unigrams and bigrams
    \item Minimum document frequency: 1
    \item Maximum document frequency: 0.95
\end{itemize}

\subsection{Topic Modeling}

\subsubsection{Latent Dirichlet Allocation (LDA)}
LDA is a generative probabilistic model that assumes:

\begin{itemize}
    \item Each document is a mixture of topics
    \item Each topic is a mixture of words
\end{itemize}

The generative process:
\begin{enumerate}
    \item For each document $d$, draw topic distribution $\theta_d \sim \text{Dir}(\alpha)$
    \item For each word position $n$ in document $d$:
    \begin{itemize}
        \item Draw topic $z_{d,n} \sim \text{Multinomial}(\theta_d)$
        \item Draw word $w_{d,n} \sim \text{Multinomial}(\beta_{z_{d,n}})$
    \end{itemize}
\end{enumerate}

Implementation parameters:
\begin{itemize}
    \item Number of topics: User-configurable (2-10)
    \item Passes: 15
    \item Alpha: auto
    \item Eta: auto
\end{itemize}

\subsubsection{K-Means Clustering}
K-Means partitions documents into $k$ clusters by minimizing:

\begin{equation}
\sum_{i=1}^{k} \sum_{x \in C_i} ||x - \mu_i||^2
\end{equation}

where $\mu_i$ is the centroid of cluster $C_i$.

Implementation:
\begin{itemize}
    \item Number of clusters: User-configurable (2-10)
    \item Initialization: k-means++
    \item Maximum iterations: 300
    \item Random state: 42 (for reproducibility)
\end{itemize}

\subsection{Keyword Extraction}

Keywords are extracted using TF-IDF scores:

\begin{algorithm}
\caption{Keyword Extraction}
\begin{algorithmic}[1]
\Procedure{ExtractKeywords}{$tfidf\_matrix, feature\_names, n$}
    \State $scores \gets \text{Sum}(tfidf\_matrix, axis=0)$
    \State $sorted\_indices \gets \text{ArgSort}(scores, descending=True)$
    \State $keywords \gets []$
    \For{$i \gets 0$ to $n-1$}
        \State $idx \gets sorted\_indices[i]$
        \State $keywords.\text{append}((feature\_names[idx], scores[idx]))$
    \EndFor
    \State \Return $keywords$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Extractive Summarization}

Three extractive summarization methods are implemented:

\subsubsection{TF-IDF Based Summarization}
Sentences are ranked by the sum of TF-IDF scores of their constituent words:

\begin{equation}
\text{Score}(s) = \sum_{w \in s} \text{TF-IDF}(w)
\end{equation}

\subsubsection{Frequency-Based Summarization}
Sentences are ranked by word frequency:

\begin{equation}
\text{Score}(s) = \sum_{w \in s} \frac{\text{count}(w)}{\max_{w'} \text{count}(w')}
\end{equation}

\subsubsection{Position-Weighted Summarization}
Combines frequency with position bias:

\begin{equation}
\text{Score}(s) = \alpha \cdot \text{FreqScore}(s) + (1-\alpha) \cdot \text{PositionScore}(s)
\end{equation}

where $\alpha = 0.7$ and earlier sentences receive higher position scores.

\subsection{Evaluation Metrics}

\subsubsection{Topic Coherence}
Coherence measures the semantic similarity between high-scoring words in topics. We use the $C_v$ measure:

\begin{equation}
C_v = \frac{1}{|T|} \sum_{t \in T} \text{coherence}(t)
\end{equation}

Higher coherence indicates more interpretable topics.

\subsubsection{Topic Diversity}
Measures the uniqueness of topics:

\begin{equation}
\text{Diversity} = \frac{|\text{unique\_words}|}{k \times n}
\end{equation}

where $k$ is the number of topics and $n$ is the number of words per topic.

\subsubsection{Compression Ratio}
For summarization:

\begin{equation}
\text{Compression} = \frac{\text{summary\_length}}{\text{original\_length}}
\end{equation}

\section{Implementation}

\subsection{Technology Stack}

\begin{table}[h]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Component} & \textbf{Technology} \\ \midrule
Programming Language & Python 3.8+ \\
Web Framework & Streamlit \\
NLP Toolkit & NLTK \\
Machine Learning & scikit-learn \\
Topic Modeling & Gensim \\
Text Processing & spaCy (optional) \\
Data Manipulation & pandas, numpy \\
Visualization & matplotlib, WordCloud \\ \bottomrule
\end{tabular}
\caption{Technology Stack}
\end{table}

\subsection{Module Descriptions}

\subsubsection{document\_loader.py}
Handles document parsing and loading from multiple formats. Supports batch processing and error handling for corrupted files.

\subsubsection{processor.py}
Implements the text preprocessing pipeline with configurable options for tokenization, lemmatization, and filtering.

\subsubsection{feature\_extractor.py}
Provides TF-IDF vectorization with n-gram support and feature statistics computation.

\subsubsection{topic\_modeler.py}
Implements LDA topic modeling using Gensim, including topic extraction, document-topic assignment, and coherence calculation.

\subsubsection{clustering.py}
Implements K-Means clustering with cluster analysis and top-term extraction per cluster.

\subsubsection{keyword\_extractor.py}
Extracts keywords using TF-IDF scores and generates automatic theme labels for topics.

\subsubsection{summarizer.py}
Provides three extractive summarization methods with configurable sentence counts and summary statistics.

\subsubsection{evaluator.py}
Computes evaluation metrics including coherence scores, topic diversity, and compression ratios.

\subsubsection{app.py}
Main Streamlit application providing an interactive web interface with real-time analysis and visualization.

\subsection{Code Example}

\begin{lstlisting}[caption=Topic Modeling Example]
from src.topic_modeler import TopicModeler

# Initialize topic modeler
modeler = TopicModeler()

# Train LDA model
model = modeler.train_lda_model(
    documents=preprocessed_tokens,
    num_topics=5,
    passes=15
)

# Extract topics
topics = modeler.get_topics(num_words=10)

# Get document-topic distribution
doc_topics = modeler.get_document_topics()

# Calculate coherence
coherence = modeler.calculate_coherence()
\end{lstlisting}

\section{Results}

\subsection{Topic Discovery}

The system successfully identifies topics from research documents. Example topics discovered:

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Topic} & \textbf{Top Keywords} \\ \midrule
Topic 0 & machine, learning, algorithm, model, training, data, neural, network \\
Topic 1 & natural, language, processing, text, semantic, syntax, parsing \\
Topic 2 & document, analysis, classification, clustering, feature, extraction \\
Topic 3 & evaluation, metric, performance, accuracy, precision, recall \\
Topic 4 & application, system, implementation, framework, tool \\ \bottomrule
\end{tabular}
\caption{Example Discovered Topics}
\end{table}

\subsection{Evaluation Metrics}

Typical performance metrics observed:

\begin{table}[h]
\centering
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Metric} & \textbf{Value} \\ \midrule
Coherence Score ($C_v$) & 0.45 - 0.65 \\
Topic Diversity & 0.70 - 0.85 \\
Compression Ratio & 0.15 - 0.30 \\
Processing Time (per doc) & 0.5 - 2.0 seconds \\ \bottomrule
\end{tabular}
\caption{Performance Metrics}
\end{table}

\subsection{Comparative Analysis}

\subsubsection{LDA vs. K-Means}

\begin{table}[h]
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Aspect} & \textbf{LDA} & \textbf{K-Means} \\ \midrule
Probabilistic & Yes & No \\
Soft Clustering & Yes & No \\
Interpretability & High & Medium \\
Computational Cost & Higher & Lower \\
Coherence & Better & Good \\
Scalability & Moderate & Excellent \\ \bottomrule
\end{tabular}
\caption{LDA vs. K-Means Comparison}
\end{table}

\section{Limitations and Challenges}

\subsection{Fundamental Limitations}

\subsubsection{No Semantic Understanding}
Traditional methods treat words as independent tokens:
\begin{itemize}
    \item Cannot recognize synonyms (e.g., "car" vs. "automobile")
    \item No understanding of word relationships
    \item Context-independent representations
\end{itemize}

\subsubsection{Context Blindness}
\begin{itemize}
    \item Cannot resolve polysemy (e.g., "bank" = financial institution vs. river bank)
    \item No discourse understanding
    \item Sentence order ignored in BoW
\end{itemize}

\subsubsection{Topic Coherence vs. Meaningfulness}
\begin{itemize}
    \item High coherence measures statistical co-occurrence, not semantic coherence
    \item Topics may group unrelated but frequently co-occurring words
    \item Automatic labeling is unreliable
\end{itemize}

\subsubsection{Preprocessing Sensitivity}
\begin{itemize}
    \item Results heavily depend on tokenization choices
    \item Stop-word lists significantly impact outcomes
    \item Lemmatization errors propagate through pipeline
\end{itemize}

\subsubsection{Summarization Constraints}
\begin{itemize}
    \item Extractive methods only copy sentences
    \item No paraphrasing or information synthesis
    \item Summaries may lack coherence
    \item Position bias favors document beginnings
\end{itemize}

\subsection{Technical Challenges}

\begin{itemize}
    \item \textbf{Hyperparameter Tuning}: Number of topics, alpha, eta require manual tuning
    \item \textbf{Scalability}: LDA becomes computationally expensive for large corpora
    \item \textbf{Short Documents}: Insufficient context for reliable topic assignment
    \item \textbf{Domain Adaptation}: Generic stop-word lists may not suit specialized domains
\end{itemize}

\section{Future Scope}

\subsection{Milestone-2: Agentic AI Integration}

The limitations identified motivate the development of advanced systems:

\subsubsection{Semantic Understanding}
\begin{itemize}
    \item Transformer-based models (BERT, RoBERTa)
    \item Contextual embeddings
    \item Semantic similarity measures
\end{itemize}

\subsubsection{Reasoning Capabilities}
\begin{itemize}
    \item Multi-step reasoning chains
    \item Fact-checking and verification
    \item Contradiction detection
    \item Cross-document synthesis
\end{itemize}

\subsubsection{Abstractive Summarization}
\begin{itemize}
    \item Paraphrasing and information fusion
    \item Coherent narrative generation
    \item Query-focused summarization
\end{itemize}

\subsubsection{Tool Use and External Knowledge}
\begin{itemize}
    \item Knowledge base integration
    \item Web search capabilities
    \item Citation and reference tracking
\end{itemize}

\subsection{Potential Enhancements}

\begin{itemize}
    \item \textbf{Hybrid Approaches}: Combine classical and modern techniques
    \item \textbf{Active Learning}: User feedback for model improvement
    \item \textbf{Multi-lingual Support}: Extend to non-English documents
    \item \textbf{Real-time Processing}: Stream processing for large document sets
    \item \textbf{Visualization}: Interactive topic exploration and document mapping
\end{itemize}

\section{Conclusion}

This project successfully demonstrates the capabilities and limitations of traditional NLP techniques for research document analysis. The implemented system provides:

\begin{itemize}
    \item A modular, extensible toolkit for classical NLP tasks
    \item Comprehensive document processing pipeline
    \item Multiple algorithms for topic modeling and summarization
    \item Interactive web interface for real-time analysis
    \item Rigorous evaluation framework
\end{itemize}

\textbf{Key Findings:}
\begin{enumerate}
    \item Traditional methods offer interpretability and computational efficiency
    \item TF-IDF and LDA provide reasonable topic discovery for well-structured documents
    \item Extractive summarization captures key sentences but lacks synthesis
    \item Fundamental limitations in semantic understanding motivate advanced approaches
\end{enumerate}

\textbf{Contribution:}
This work establishes a baseline for evaluating future AI-driven systems and clearly demonstrates why semantic understanding and reasoning capabilities are essential for advanced document analysis.

The limitations identified—lack of semantic understanding, context blindness, and inability to synthesize information—provide strong motivation for developing Agentic AI systems in subsequent milestones.

\section*{Acknowledgments}

This project was developed as part of a research initiative exploring the evolution of NLP techniques from classical to modern approaches. Special thanks to the open-source community for providing excellent libraries and tools.

\begin{thebibliography}{9}

\bibitem{blei2003lda}
Blei, D. M., Ng, A. Y., \& Jordan, M. I. (2003).
\textit{Latent dirichlet allocation}.
Journal of Machine Learning Research, 3, 993-1022.

\bibitem{salton1988tfidf}
Salton, G., \& Buckley, C. (1988).
\textit{Term-weighting approaches in automatic text retrieval}.
Information Processing \& Management, 24(5), 513-523.

\bibitem{roder2015coherence}
Röder, M., Both, A., \& Hinneburg, A. (2015).
\textit{Exploring the space of topic coherence measures}.
Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, 399-408.

\bibitem{luhn1958automatic}
Luhn, H. P. (1958).
\textit{The automatic creation of literature abstracts}.
IBM Journal of Research and Development, 2(2), 159-165.

\bibitem{bird2009nltk}
Bird, S., Klein, E., \& Loper, E. (2009).
\textit{Natural language processing with Python: Analyzing text with the natural language toolkit}.
O'Reilly Media, Inc.

\bibitem{rehurek2010gensim}
Řehůřek, R., \& Sojka, P. (2010).
\textit{Software framework for topic modelling with large corpora}.
Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks.

\bibitem{pedregosa2011scikit}
Pedregosa, F., et al. (2011).
\textit{Scikit-learn: Machine learning in Python}.
Journal of Machine Learning Research, 12, 2825-2830.

\bibitem{macqueen1967kmeans}
MacQueen, J. (1967).
\textit{Some methods for classification and analysis of multivariate observations}.
Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, 1(14), 281-297.

\end{thebibliography}

\end{document}
